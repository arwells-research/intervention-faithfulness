Method invariants (non-negotiable)
I1) Purely empirical, model-agnostic

The diagnostic uses only measured trials.

No simulation, no microscopic assumptions, no curve fitting required.

I2) The target is intervention faithfulness of a reduced state representation

We test whether a chosen mapping 
ğ‘ 
ğ‘¡
=
ğ‘…
(
ğ‘¦
0
:
ğ‘¡
)
s
t
	â€‹

=R(y
0:t
	â€‹

) is sufficient to support prediction under intervention.

The state can be â€œwhatever the model interface currently usesâ€ (state_* columns).

I3) What is being tested is distributional invariance, not determinism

The criterion is: for histories 
â„
1
,
â„
2
h
1
	â€‹

,h
2
	â€‹

 that collapse to the same reduced state, the conditional continuation distributions under the same intervention must match.

This defuses â€œstochasticityâ€ objections: randomness is fine if the conditional distribution is invariant.

I4) Continuation fracture is a regime-dependent signature of representational collapse

Fracture is not â€œnoiseâ€ or â€œnon-Markovianity in general.â€

It is the empirical signature that the reduction collapsed histories that are continuation-relevant under intervention.

I5) The primary output is operational, not interpretive

Faithfulness maps + safe envelope + certificate are meant to answer:

â€œWhen is my state good enough?â€

â€œWhere does it fail?â€

â€œWhat minimal augmentation restores validity?â€

Canonical data contract (what the core assumes)

Your collaboratorâ€™s plugin-layer proposal matches the method perfectly:

Required

trial_id

intervention_id (categorical or numeric)

outcome (scalar; vector later if needed)

state_* columns (the candidate reduced state)

Optional

history_* columns (full-history descriptors / engineered features / labels)

Invariant: the core operates on this canonical table. Everything else is adapters.

Metrics (what â€œfractureâ€ means, in v0.1 terms)

You have two conceptions now; both are consistent with the original METHODS:

M1) Refinement fracture (state vs history refinement)

Interpretation: â€œhow much additional predictive structure exists inside the collapsed state when you condition on a finer key.â€

Compare 
ğ‘ƒ
(
ğ‘¦
âˆ£
ğ‘ 
,
ğ¼
)
P(yâˆ£s,I) vs 
ğ‘ƒ
(
ğ‘¦
âˆ£
â„
,
ğ¼
)
P(yâˆ£h,I) where 
â„
h refines 
ğ‘ 
s.

This matches your initial implementation style (state_key vs history_key refinement).

M2) Pairwise fracture (within-state pairwise divergence)

Interpretation: â€œdo different history classes inside the same state yield different continuation distributions?â€

For a given 
ğ‘ 
,
ğ¼
s,I, sample pairs of history classes 
â„
ğ‘–
,
â„
ğ‘—
âŠ‚
ğ»
(
ğ‘ 
)
h
i
	â€‹

,h
j
	â€‹

âŠ‚H(s) and compute 
ğ·
(
ğ‘ƒ
(
ğ‘¦
âˆ£
â„
ğ‘–
,
ğ¼
)
â€‰
âˆ¥
â€‰
ğ‘ƒ
(
ğ‘¦
âˆ£
â„
ğ‘—
,
ğ¼
)
)
D(P(yâˆ£h
i
	â€‹

,I)âˆ¥P(yâˆ£h
j
	â€‹

,I)).

This matches your â€œpairwise fracture implementation cleanlyâ€ track and the n_pairwise_pairs knob.

Invariant: both are legal operationalizations of â€œcontinuation fracture,â€ and the paper can present one as primary and the other as robustness.

Recommendations (minimal completion) invariants
R1) Recommendations are repair suggestions, not causal explanations

They propose state augmentation candidates that reduce fracture.

They do not claim â€œthis is the true microscopic state.â€

R2) Two modes

Single: rank individual candidate features by fracture reduction 
Î”
ğ¹
Î”F.

Greedy/sets: rank small sets of features that jointly reduce fracture (your rank_minimal_completion_sets path).

R3) A valid â€œnegative controlâ€ behavior exists

In a faithful regime, the recommender should often return:

empty or near-zero deltas,

â€œno action neededâ€ (or low-confidence suggestions).
This is part of the scientific contract that the method isnâ€™t a fishing expedition.

Maps / envelope / certificate invariants
V1) Faithfulness maps are â€œboundary of validityâ€ views

Grid over (x,y) axes (intervention strength, history depth/feature, etc.).

Color is fracture or normalized faithfulness.

V2) Safe envelope is a summary of the map, not a new metric

It reduces the 2D grid into human-actionable segments: safe / unsafe / uncertain.

â€œUncertainâ€ is explicitly underpowered (min_samples or NaN).

V3) Certificates must be auditable artifacts

Include hashes of trials table + diagnosis record.

Export bundle should contain:

diagnosis JSON

certificate JSON (curated payload)

optional PDF/HTML certificate

map image(s)

any metadata/config provenance

Phase structure for the paper (the Aâ†’Bâ†’Câ†’Dâ†’E arc)

This is the minimum â€œsection header skeletonâ€ implied by your dialog:

Recognized failure mode (protocol dependence / regime dependence)

Method: invariance of conditional continuation distributions

Metric: continuation fracture + significance + sample warnings

Repair: minimal completion (single + greedy sets)

Operationalization: maps â†’ safe envelope â†’ certificate

Validation of the validator: negative control regime

This keeps nanowires as â€œcanonical positive caseâ€ while remaining a general methods paper.